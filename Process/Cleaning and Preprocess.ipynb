{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from keras.layers import Dense, Input, LSTM, GRU, Conv1D, Dropout, Flatten, Layer, BatchNormalization\n",
    "import string\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim import models\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts\n",
       "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n",
       "1  ENTP  'I'm finding the lack of me in these posts ver...\n",
       "2  INTP  'Good one  _____   https://www.youtube.com/wat...\n",
       "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...\n",
       "4  ENTJ  'You're fired.|||That's another silly misconce..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing Data\n",
    "df = pd.read_csv('mbti_1.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MBTI exsit in 4 different Categories having Two classes, we will be sepearting into Four Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First Section is E and I seperation (First Section of MBTI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperating Type of MBTI to Binary (E and I)\n",
    "def binary_seperation(dataset, mbti_type1, mbti_type2):\n",
    "    for i in range(len(df['type'])):\n",
    "        if mbti_type1 in dataset['type'].iloc[i]:\n",
    "            dataset['type'].iloc[i] = mbti_type1\n",
    "        else:\n",
    "            dataset['type'].iloc[i] = mbti_type2\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  type                                              posts\n",
       "0    I  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n",
       "1    E  'I'm finding the lack of me in these posts ver...\n",
       "2    I  'Good one  _____   https://www.youtube.com/wat...\n",
       "3    I  'Dear INTP,   I enjoyed our conversation the o...\n",
       "4    E  'You're fired.|||That's another silly misconce..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ei = binary_seperation(df, 'E', 'I')\n",
    "ei.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When doing NLP, the Website link does not give inutitive information when predicting, we will be removing the Website links to each posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Text with website link and expanding each user's posts\n",
    "# one row = one user having 50 different posts --> 1 Row with one post with corresponding MBTI Type\n",
    "intravert = []\n",
    "extravert = []\n",
    "for i in range(len(ei)):\n",
    "    if df['type'].iloc[i] == 'I':\n",
    "        split = df['posts'].iloc[i].split('|||')\n",
    "        for sentence in split:\n",
    "            if 'http' not in sentence:\n",
    "                intravert.append(sentence)\n",
    "                \n",
    "    else:\n",
    "        split = df['posts'].iloc[i].split('|||')\n",
    "        for sentence in split:\n",
    "            if 'http' not in sentence:\n",
    "                extravert.append(sentence)\n",
    "    \n",
    "I = pd.DataFrame(intravert, columns = ['Posts'])\n",
    "I['type'] = 'I'\n",
    "\n",
    "E = pd.DataFrame(extravert, columns = ['Posts'])\n",
    "E['type'] = 'E'\n",
    "\n",
    "eiei = pd.concat([I, E])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Posts</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What has been the most life-changing experienc...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>May the PerC Experience immerse you.</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hello ENFJ7. Sorry to hear of your distress. I...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Welcome and stuff.</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Prozac, wellbrutin, at least thirty minutes of...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Posts type\n",
       "0  What has been the most life-changing experienc...    I\n",
       "1               May the PerC Experience immerse you.    I\n",
       "2  Hello ENFJ7. Sorry to hear of your distress. I...    I\n",
       "3                                 Welcome and stuff.    I\n",
       "4  Prozac, wellbrutin, at least thirty minutes of...    I"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eiei.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before Feature Extraction, the text must be preprocessed:\n",
    "1. Removing Stop Words\n",
    "2. Removing Punctuations\n",
    "3. Apply Stemming\n",
    "4. Apply Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that Takes in the Text (in sentence) and remove unecessary portion from the text\n",
    "def text_preprocess(headlines):\n",
    "    #Tokenizing Each headlines \n",
    "    token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "\n",
    "    tokenized = []\n",
    "    \n",
    "    #Tokenizing + Number Removal\n",
    "    for i in range(len(headlines)):\n",
    "        tokens = token.tokenize(headlines.iloc[i])\n",
    "        num_remove = [i for i in tokens if i.isalpha()]\n",
    "        tokenized.append(num_remove)\n",
    "        \n",
    "    #Stop words and Punctuation removal\n",
    "    st = stopwords.words('english')\n",
    "    punctuations = string.punctuation\n",
    "    processed = []\n",
    "    \n",
    "    for i in range(len(tokenized)):\n",
    "        words = [word for word in tokenized[i] if word.lower() not in st and word not in punctuations]\n",
    "        #Num Removal\n",
    "        new_text = \" \".join(words)\n",
    "        processed.append(new_text)\n",
    "    \n",
    "    #Stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed = []\n",
    "    \n",
    "    for i in processed:\n",
    "        stem_word = stemmer.stem(i)\n",
    "        stemmed.append(stem_word)\n",
    "    \n",
    "    #Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized = []\n",
    "    \n",
    "    for i in stemmed:\n",
    "        lemmatize_word = lemmatizer.lemmatize(i)\n",
    "        lemmatized.append(lemmatize_word)\n",
    "      \n",
    "    return lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Posts</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>life changing experience lif</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>may perc experience immers</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hello sorry hear distress natural relationship...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>welcome stuff</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>prozac wellbrutin least thirty minutes moving ...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Posts type\n",
       "0                       life changing experience lif    I\n",
       "1                         may perc experience immers    I\n",
       "2  hello sorry hear distress natural relationship...    I\n",
       "3                                      welcome stuff    I\n",
       "4  prozac wellbrutin least thirty minutes moving ...    I"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed = text_preprocess(eiei['Posts'])\n",
    "eiei['Posts'] = preprocessed\n",
    "eiei.reset_index(inplace = True, drop=True)\n",
    "eiei.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When text sizes are too Small Ex. Less than 2, it will not provide a enough information when predicting, removing the posts with less than 2 words will be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing the sentence with less than or equal to 2 words (this will not provide inutitive information)\n",
    "drop = []\n",
    "for i in range(len(eiei['Posts'])):\n",
    "    if len(eiei['Posts'].iloc[i].split()) <= 2:\n",
    "        drop.append(i)\n",
    "\n",
    "eiei.drop(drop, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The data had ~8700 Rows (Sample Size) but each row contained 50 different posts within a single row, I have decided to expand this to make more datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Posts</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>life changing experience lif</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>may perc experience immers</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hello sorry hear distress natural relationship...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>prozac wellbrutin least thirty minutes moving ...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>basically come three items determined type whi...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397609</th>\n",
       "      <td>knit craft long craft simple complicated patte...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397610</th>\n",
       "      <td>quote kevinaswell say green grape soda say huh...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397611</th>\n",
       "      <td>true sort hahah goes cycles spurts interest</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397612</th>\n",
       "      <td>dear anonymous es hire great asset possible fu...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397613</th>\n",
       "      <td>lovelife nonexistant recently basically since ...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>370832 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Posts type\n",
       "0                            life changing experience lif    I\n",
       "1                              may perc experience immers    I\n",
       "2       hello sorry hear distress natural relationship...    I\n",
       "4       prozac wellbrutin least thirty minutes moving ...    I\n",
       "5       basically come three items determined type whi...    I\n",
       "...                                                   ...  ...\n",
       "397609  knit craft long craft simple complicated patte...    E\n",
       "397610  quote kevinaswell say green grape soda say huh...    E\n",
       "397611        true sort hahah goes cycles spurts interest    E\n",
       "397612  dear anonymous es hire great asset possible fu...    E\n",
       "397613  lovelife nonexistant recently basically since ...    E\n",
       "\n",
       "[370832 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eiei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
