{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from keras.layers import Dense, Input, LSTM, GRU, Conv1D, Dropout, Flatten, Layer, BatchNormalization\n",
    "import string\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim import models\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from imblearn.pipeline import Pipeline \n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from imblearn.metrics import classification_report_imbalanced \n",
    "from sklearn.svm import LinearSVC\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('EI.csv')\n",
    "I = 284212\n",
    "E = 10827\n",
    "testing = pd.concat([df.iloc[:35526], df.iloc[I:I + E]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that evaluates the model based on the confusion matrix and accuracy score\n",
    "def evaluation(X, y, model):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "    \n",
    "    model.fit(X_train,y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    print('Accuracy Score:{}'.format(accuracy_score(y_test, y_pred)) )\n",
    "    print(classification_report_imbalanced(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression \n",
    "\n",
    "logistic_regression = Pipeline([('Undersample', RandomUnderSampler()), \n",
    "                                ('Logistic', LogisticRegression())])\n",
    "\n",
    "# Support Vector Machine - L1 Regularized\n",
    "svm_lasso = Pipeline([('Undersample', RandomUnderSampler()),\n",
    "                    ('LinearSVC', LinearSVC(penalty='l1', dual=False))])\n",
    "\n",
    "#Support Vector Machine - L2 Regularized\n",
    "svm_ridge = Pipeline([('Undersample', RandomUnderSampler()),\n",
    "                    ('LinearSVC', LinearSVC(penalty='l2', dual=False))])\n",
    "\n",
    "# Random Forest\n",
    "rf = Pipeline([('Undersample', RandomUnderSampler()),\n",
    "            ('RandomForest', RandomForestClassifier(n_estimators=100, max_depth=10))])\n",
    "\n",
    "# Naive Bayes\n",
    "nb = Pipeline([('Undersample', RandomUnderSampler()),\n",
    "            ('NaiveBayes', MultinomialNB())]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = pd.read_csv('bow.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Input and Output\n",
    "X_bow = bow\n",
    "le = preprocessing.LabelEncoder()\n",
    "y = le.fit_transform(testing['type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:0.5570799896453533\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.28      0.56      0.56      0.37      0.56      0.31      2754\n",
      "          1       0.80      0.56      0.56      0.66      0.56      0.31      8835\n",
      "\n",
      "avg / total       0.68      0.56      0.56      0.59      0.56      0.31     11589\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation(X_bow, y, logistic_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM - L1 Regularized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:0.552851842264216\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.28      0.57      0.55      0.38      0.56      0.31      2754\n",
      "          1       0.80      0.55      0.57      0.65      0.56      0.31      8835\n",
      "\n",
      "avg / total       0.68      0.55      0.56      0.59      0.56      0.31     11589\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation(X_bow, y, svm_lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM - L2 Regularized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:0.5424109068944689\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.27      0.54      0.54      0.36      0.54      0.29      2754\n",
      "          1       0.79      0.54      0.54      0.64      0.54      0.29      8835\n",
      "\n",
      "avg / total       0.67      0.54      0.54      0.58      0.54      0.29     11589\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation(X_bow, y, svm_ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:0.6819397704719993\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.33      0.34      0.79      0.34      0.52      0.25      2754\n",
      "          1       0.79      0.79      0.34      0.79      0.52      0.28      8835\n",
      "\n",
      "avg / total       0.68      0.68      0.44      0.68      0.52      0.27     11589\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation(X_bow, y, rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:0.5676935024592286\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.29      0.56      0.57      0.38      0.56      0.32      2754\n",
      "          1       0.81      0.57      0.56      0.67      0.56      0.32      8835\n",
      "\n",
      "avg / total       0.68      0.57      0.56      0.60      0.56      0.32     11589\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation(X_bow, y, nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we have used Undersampling method to have equal distribution of clas 0 and 1, the prediction on Class 0 (Extrovert) does not perform well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = pd.read_csv('tfidf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf = tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:0.575804642333247\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.29      0.53      0.59      0.37      0.56      0.31      2754\n",
      "          1       0.80      0.59      0.53      0.68      0.56      0.32      8835\n",
      "\n",
      "avg / total       0.68      0.58      0.55      0.61      0.56      0.31     11589\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation(X_tfidf, y, logistic_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM - L1 Regularized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:0.5598412287514022\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.28      0.55      0.56      0.37      0.56      0.31      2754\n",
      "          1       0.80      0.56      0.55      0.66      0.56      0.31      8835\n",
      "\n",
      "avg / total       0.68      0.56      0.55      0.59      0.56      0.31     11589\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation(X_tfidf,y, svm_lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM - L2 Regularized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:0.5489688497713349\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.28      0.55      0.55      0.37      0.55      0.30      2754\n",
      "          1       0.80      0.55      0.55      0.65      0.55      0.30      8835\n",
      "\n",
      "avg / total       0.67      0.55      0.55      0.58      0.55      0.30     11589\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation(X_tfidf,y, svm_ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:0.6823712140823195\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.33      0.33      0.79      0.33      0.51      0.25      2754\n",
      "          1       0.79      0.79      0.33      0.79      0.51      0.28      8835\n",
      "\n",
      "avg / total       0.68      0.68      0.44      0.68      0.51      0.27     11589\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation(X_tfidf,y, rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:0.559237207696954\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.29      0.58      0.55      0.38      0.57      0.32      2754\n",
      "          1       0.81      0.55      0.58      0.66      0.57      0.32      8835\n",
      "\n",
      "avg / total       0.68      0.56      0.57      0.59      0.57      0.32     11589\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation(X_tfidf,y, nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is not significant difference between BOW and TFIDF and also the undersampling method, provide bad precision score for class 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying SMOTE - Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE()\n",
    "X_os, y_os = oversample.fit_resample(X_tfidf, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:0.7303383437482407\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.74      0.71      0.75      0.72      0.73      0.53      8864\n",
      "          1       0.72      0.75      0.71      0.74      0.73      0.53      8899\n",
      "\n",
      "avg / total       0.73      0.73      0.73      0.73      0.73      0.53     17763\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "evaluation(X_os, y_os, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM - L1 Regularized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:0.7308450149186512\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.74      0.72      0.75      0.73      0.73      0.53      8864\n",
      "          1       0.72      0.75      0.72      0.74      0.73      0.54      8899\n",
      "\n",
      "avg / total       0.73      0.73      0.73      0.73      0.73      0.53     17763\n",
      "\n"
     ]
    }
   ],
   "source": [
    "l1 = LinearSVC(penalty='l1',dual=False)\n",
    "evaluation(X_os, y_os, l1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM - L2 Regularized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:0.7309013117153634\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.74      0.71      0.75      0.73      0.73      0.53      8864\n",
      "          1       0.72      0.75      0.71      0.74      0.73      0.54      8899\n",
      "\n",
      "avg / total       0.73      0.73      0.73      0.73      0.73      0.53     17763\n",
      "\n"
     ]
    }
   ],
   "source": [
    "l2 = LinearSVC(penalty='l2',dual=False)\n",
    "evaluation(X_os, y_os, l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:0.6871024038732196\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.67      0.73      0.65      0.70      0.69      0.47      8864\n",
      "          1       0.70      0.65      0.73      0.67      0.69      0.47      8899\n",
      "\n",
      "avg / total       0.69      0.69      0.69      0.69      0.69      0.47     17763\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, max_depth=10)\n",
    "evaluation(X_os, y_os, rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:0.6086246692563193\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.61      0.59      0.62      0.60      0.61      0.37      8864\n",
      "          1       0.61      0.62      0.59      0.61      0.61      0.37      8899\n",
      "\n",
      "avg / total       0.61      0.61      0.61      0.61      0.61      0.37     17763\n",
      "\n"
     ]
    }
   ],
   "source": [
    "naive = MultinomialNB()\n",
    "evaluation(X_os, y_os, naive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the results are better with oversampling (SMOTE) technique which significantly lncrease the precision score for class 0.\n",
    "<br>\n",
    "The overall accuracy score also increased with SMOTE and showing the Linear seperation method works better (Logistic, SVM) than ensemble and naive bayes model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec - Pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = pd.read_csv('word2v.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Logistic Regressionoversampling\n",
    "oversample = SMOTE()\n",
    "X_w2v, y_w2v = oversample.fit_resample(word2vec, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:0.5952260316387997\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.59      0.62      0.57      0.60      0.59      0.36      8864\n",
      "          1       0.60      0.57      0.62      0.59      0.59      0.35      8899\n",
      "\n",
      "avg / total       0.60      0.60      0.60      0.60      0.59      0.35     17763\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation(X_w2v, y_w2v, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM - L1 Regularized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:0.5959578899960593\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.59      0.62      0.57      0.61      0.60      0.36      8864\n",
      "          1       0.60      0.57      0.62      0.59      0.60      0.35      8899\n",
      "\n",
      "avg / total       0.60      0.60      0.60      0.60      0.60      0.35     17763\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation(X_w2v, y_w2v, l1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM - L2 Regularized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:0.5964645611664696\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.59      0.62      0.57      0.61      0.60      0.36      8864\n",
      "          1       0.60      0.57      0.62      0.59      0.60      0.35      8899\n",
      "\n",
      "avg / total       0.60      0.60      0.60      0.60      0.60      0.36     17763\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation(X_w2v, y_w2v, l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:0.69306986432472\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.69      0.70      0.68      0.70      0.69      0.48      8864\n",
      "          1       0.70      0.68      0.70      0.69      0.69      0.48      8899\n",
      "\n",
      "avg / total       0.69      0.69      0.69      0.69      0.69      0.48     17763\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation(X_w2v, y_w2v, rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretraiend Word2vec model performance was not great overall and was in fact lower than tfidf with SMOTE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid - Word2Vec * TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid = pd.read_csv('hybrid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE()\n",
    "X_hybrid, y_hybrid = oversample.fit_resample(hybrid, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:0.71119743286607\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.69      0.76      0.66      0.72      0.71      0.51      8864\n",
      "          1       0.74      0.66      0.76      0.70      0.71      0.50      8899\n",
      "\n",
      "avg / total       0.71      0.71      0.71      0.71      0.71      0.50     17763\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation(X_hybrid, y_hybrid, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:0.708044812250183\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.68      0.77      0.65      0.72      0.71      0.50      8864\n",
      "          1       0.74      0.65      0.77      0.69      0.71      0.49      8899\n",
      "\n",
      "avg / total       0.71      0.71      0.71      0.71      0.71      0.50     17763\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation(X_hybrid, y_hybrid, l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:0.7076507346731971\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.68      0.77      0.65      0.72      0.71      0.50      8864\n",
      "          1       0.74      0.65      0.77      0.69      0.71      0.49      8899\n",
      "\n",
      "avg / total       0.71      0.71      0.71      0.71      0.71      0.50     17763\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation(X_hybrid, y_hybrid, l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:0.7548837471147891\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.76      0.75      0.76      0.75      0.75      0.57      8864\n",
      "          1       0.75      0.76      0.75      0.76      0.75      0.57      8899\n",
      "\n",
      "avg / total       0.75      0.75      0.75      0.75      0.75      0.57     17763\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation(X_hybrid, y_hybrid, rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results show that hybrid mechansim works well with this data and Random Forest had the highest prediction score. We can try to implement Boosting techniques to see if other tree models works better or do Hyperparameter tunning to increase the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
